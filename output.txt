[2.392371196994922, 1.0766551674987275, 0.7221134935511333, 0.5368943908741808, 0.44254198483602636, 0.3502589320991147, 0.30964874339036313, 0.2418022349670652, 0.2280310195649522, 0.17975064759552256]
[1.5433615792769118, 0.8401380524092066, 0.7680352525925175, 0.601984480417743, 0.326005180002591, 0.47266864608064535, 0.5907685700149099, 0.1817370706630536, 2.5681589467871837, 0.16222626800578047]
[0.39022064832470715, 0.6749523290656497, 0.777497786555881, 0.8315058230606824, 0.8599741197303004, 0.8887148402914936, 0.8987945242797793, 0.9224954028468296, 0.9252877477354764, 0.9426547708234012]
[0.5641864268192968, 0.7421640774052876, 0.7647860452439357, 0.8179340419732897, 0.8887980376124285, 0.8498228400109021, 0.8160261651676206, 0.9400381575361134, 0.43008994276369583, 0.9452166802943581]





import csv
import os
import shutil
import sys

import numpy as np
import pandas as pd
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from matplotlib import pyplot as plt
from torch import nn
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm

# 使用预训练的resnet18模型
model = models.resnet18(pretrained=True)
# 获取模型的输入特征数
in_features = model.fc.in_features
# 修改模型的全连接层，使其输出特征数为176
model.fc = nn.Linear(in_features, 176)

# 读取标签数据
labels_dataframe = pd.read_csv('D:/python code/deep_learn/data/classify-leaves/train.csv')
# 获取所有的标签，并排序
leaves_labels = sorted(list(set(labels_dataframe['label'])))
# 获取标签的数量
n_classes = len(leaves_labels)
# 创建一个字典，将标签映射到一个数字
class_to_num = dict(zip(leaves_labels, range(n_classes)))
# 创建一个字典，将数字映射回标签
num_to_class = {v: k for k, v in class_to_num.items()}


# 创建一个继承自pytorch的dataset的类
class LeavesData(Dataset):
    def __init__(self, csv_path, file_path, k=0, mode='train', valid_ratio=0.2, resize_height=256, resize_width=256):
        """
        Args:
            csv_path (string): csv 文件路径
            img_path (string): 图像文件所在路径
            mode (string): 训练模式还是测试模式
            valid_ratio (float): 验证集比例
        """

        # 需要调整后的照片尺寸，我这里每张图片的大小尺寸不一致#
        self.resize_height = resize_height
        self.resize_width = resize_width

        self.file_path = file_path
        self.k = k
        self.mode = mode

        # 读取 csv 文件
        # 利用pandas读取csv文件
        self.data_info = pd.read_csv(csv_path, header=None)  # header=None是去掉表头部分
        # 计算 length
        self.data_len = len(self.data_info.index) - 1
        self.train_len = int(self.data_len * valid_ratio) - 1

        if mode == 'train':
            # 第一列包含图像文件的名称,self.data_info.iloc[1:,0]表示读取第一列，从第二行开始到train_len
            self.train_image = np.asarray(pd.concat([self.data_info.iloc[1:self.k * self.train_len, 0],
                                                     self.data_info.iloc[1 + (self.k + 1) * self.train_len:, 0]]))
            # 第二列是图像的 label
            self.train_label = np.asarray(pd.concat([self.data_info.iloc[1:self.k * self.train_len, 1],
                                                     self.data_info.iloc[1 + (self.k + 1) * self.train_len:, 1]]))
            self.image_arr = self.train_image
            self.label_arr = self.train_label
        elif mode == 'valid':
            self.valid_image = np.asarray(
                self.data_info.iloc[1 + self.k * self.train_len:1 + (self.k + 1) * self.train_len, 0])
            self.valid_label = np.asarray(
                self.data_info.iloc[1 + self.k * self.train_len:1 + (self.k + 1) * self.train_len, 1])
            self.image_arr = self.valid_image
            self.label_arr = self.valid_label
        elif mode == 'test':
            self.test_image = np.asarray(self.data_info.iloc[1:, 0])
            self.image_arr = self.test_image

        self.real_len = len(self.image_arr)

        print('Finished reading the {} set of Leaves Dataset ({} samples found)'
              .format(mode, self.real_len))

    def __getitem__(self, index):
        # 从 image_arr中得到索引对应的文件名
        single_image_name = self.image_arr[index]

        # 读取图像文件
        img_as_img = Image.open(self.file_path + single_image_name)

        # 如果需要将RGB三通道的图片转换成灰度图片可参考下面两行
        #         if img_as_img.mode != 'L':
        #             img_as_img = img_as_img.convert('L')

        # 设置好需要转换的变量，还可以包括一系列的nomarlize等等操作
        if self.mode == 'train':
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.RandomHorizontalFlip(p=0.5),  # 随机水平翻转 选择一个概率
                transforms.RandomVerticalFlip(p=0.5),
                transforms.ToTensor()
            ])
        else:
            # valid和test不做数据增强
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor()
            ])

        img_as_img = transform(img_as_img)

        if self.mode == 'test':
            return img_as_img
        else:
            # 得到图像的 string label
            label = self.label_arr[index]
            # number label
            number_label = class_to_num[label]

            return img_as_img, number_label  # 返回每一个index对应的图片数据和对应的label

    def __len__(self):
        return self.real_len


# 设置训练的epoch数，batch size和学习率
num_epochs = 2
batch_size = 16
lr = 0.05

# 设置环境变量，使得GPU可用
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

# 如果GPU可用，初始化GPU
if torch.cuda.is_available():
    torch.cuda.init()
    print('GPU available')

# 设置设备为GPU或者CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# 将模型移动到设备上（如GPU）
model.to(device)

# 设置训练和测试数据的路径
train_path = 'D:/python code/deep_learn/data/classify-leaves/train.csv'
test_path = 'D:/python code/deep_learn/data/classify-leaves/test.csv'
# csv文件中已经images的路径了，因此这里只到上一级目录
img_path = 'D:/python code/deep_learn/data/classify-leaves/'


# 定义训练函数
def train_ch_def(net, num_epochs, lr, device):
    # 定义损失函数为交叉熵损失
    loss = torch.nn.CrossEntropyLoss()
    # 定义优化器为SGD
    optimizer = torch.optim.SGD(net.parameters(), lr=lr)
    # 将模型移动到设备上
    net = net.to(device)

    # 初始化训练和验证的损失和准确率
    train_losses = []
    train_accuracies = []
    valid_losses = []
    valid_accuracies = []


    for i in range(5):
        # 创建训练和验证的数据集
        train_dataset = LeavesData(train_path, img_path, k=i, mode='train')
        val_dataset = LeavesData(train_path, img_path, k=i, mode='valid')

        # 创建训练和验证的数据加载器
        train_iter = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)  # 表示随机洗牌读数
        val_iter = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)

        for epoch in range(num_epochs):
            # 设置模型为训练模式
            net.train()
            # 初始化训练的损失和准确率
            train_loss, train_acc, n = 0.0, 0.0, 0

            # 创建一个进度条
            train_bar = tqdm(train_iter,file=sys.stdout)
            for X, y in train_bar:
                # 将数据移动到设备上
                X = X.to(device)
                y = y.to(device)
                # 清空梯度
                optimizer.zero_grad()
                # 前向传播
                y_hat = net(X)
                # 计算损失
                l = loss(y_hat, y)
                # 反向传播
                l.backward()
                # 更新参数
                optimizer.step()
                # 累加损失和准确率
                train_loss += l.item() * y.shape[0]
                train_acc += (y_hat.argmax(dim=1) == y).sum().item()
                # 累加样本数
                n += y.shape[0]
                # 更新进度条
                train_bar.desc = 'train epoch[{}/{}] loss:{:.3f}' \
                    .format(epoch + 1, num_epochs, l)


            # 设置模型为评估模式
            net.eval()
            # 初始化验证的损失和准确率
            val_loss, val_acc, m = 0.0, 0.0, 0
            # 创建一个进度条
            val_bar = tqdm(val_iter, file=sys.stdout)
            for X, y in val_bar:
                # 将数据移动到设备上
                X = X.to(device)
                y = y.to(device)
                # 不计算梯度
                with torch.no_grad():
                    # 前向传播
                    y_hat = net(X)
                    # 计算损失
                    l = loss(y_hat, y)
                    # 累加损失和准确率
                    val_loss += l.item() * y.shape[0]
                    val_acc += (y_hat.argmax(dim=1) == y).sum().item()
                    # 累加样本数
                    m += y.shape[0]
                    # 更新进度条
                    val_bar.desc = 'valid epoch[{}/{}]'.format(epoch + 1, num_epochs)

            # 计算平均损失和准确率
            train_loss /= n
            train_acc /= n
            val_loss /= m
            val_acc /= m
            # 保存训练和验证的损失和准确率
            train_losses.append(train_loss)
            train_accuracies.append(train_acc)
            valid_accuracies.append(val_acc)
            valid_losses.append(val_loss)


            # 打印训练和验证的损失和准确率
            print(f"Epoch {i + 1}.{epoch + 1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f},"
                  f"Val Loss = {val_loss: .4f}, Val Acc = {val_acc: .4f}")

            # 将训练和验证的损失和准确率写入文件
            with open('output.txt', 'w') as f:
                print(train_losses, file=f)
                print(valid_losses, file=f)
                print(train_accuracies, file=f)
                print(valid_accuracies, file=f)


# 训练模型
train_ch_def(model, num_epochs, lr, device)
# 保存模型
torch.save(model.state_dict(), './working/resnet18.pth')

# 定义源文件路径和目标路径
source_file = 'D:/python code/deep_learn/data/classify-leaves/sample_submission.csv'
destination_folder = './working/sample_submission.csv'

# 使用shutil.copy()函数复制文件
shutil.copy(source_file, destination_folder)

# 加载模型进行测试，并且把文件输出到csv提交文件里

# 加载模型
model.load_state_dict(torch.load('./working/resnet18.pth'))
# 设置模型为评估模式
model.eval()

# 设置测试数据的路径
test_path = 'D:/python code/deep_learn/data/classify-leaves/test.csv'
# csv文件中已经images的路径了，因此这里只到上一级目录
img_path = 'D:/python code/deep_learn/data/classify-leaves/'

# 创建测试数据集
test_dataset = LeavesData(test_path, img_path, k=0, mode='test')
# 创建测试数据加载器
test_iter = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# 设置设备为GPU或者CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# 将模型移动到设备
model.to(device)

# 定义csv文件的路径
csv_file = './working/sample_submission.csv'
num = 0

# 打开csv文件
with open(csv_file, 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['image', 'label'])  # 写入表头

# 对测试数据进行预测
for images in test_iter:
    # 对图像进行预处理
    images = images.to(device)
    # 前向传播
    outputs = model(images)
    # 获取预测结果
    _, predicted = torch.max(outputs, 1)

    # 打印预测结果
    # print(num_to_class[predicted])
    # 将预测结果转换为类别
    class_predictions = [num_to_class[i.item()] for i in predicted]

    # 将预测结果写入csv文件
    with open(csv_file, 'a', newline='') as file:
        writer = csv.writer(file)
        if file.tell() == 0:  # 检查文件是否为空
            writer.writerow(['image', 'label'])  # 写入表头
        for index, element in enumerate(class_predictions):
            writer.writerow([f'images/{18353 + index + num}.jpg', element])
    num += batch_size

# 打印csv文件的路径
print("列表元素已写入CSV文件：", csv_file)

# 查看预测结果
predict=pd.read_csv('./working/sample_submission.csv')

# 打印预测结果
print(predict)